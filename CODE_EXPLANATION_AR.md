# Ø´Ø±Ø­ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…Ù‡Ù…Ø© - IntelliAttend

## ğŸ Backend Code Explanation

### 1. FirebaseFaceModel Class

```python
class FirebaseFaceModel:
    def __init__(self):
        # Ù‚ÙˆØ§Ø¦Ù… Ù„ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.known_face_encodings = []  # Ù‚Ø§Ø¦Ù…Ø© encodings (128 Ø±Ù‚Ù… Ù„ÙƒÙ„ ÙˆØ¬Ù‡)
        self.known_face_names = []      # Ù‚Ø§Ø¦Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†
        self.known_face_ids = []        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©
        self.firebase_service = FirebaseService()  # Ø§ØªØµØ§Ù„ Firebase
```

**Ù„Ù…Ø§Ø°Ø§ Ù†Ø®Ø²Ù† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŸ**
- Ù„Ù„Ø³Ø±Ø¹Ø©: Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø£Ø³Ø±Ø¹ Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Firebase ÙƒÙ„ Ù…Ø±Ø©
- Ù„Ù„ÙƒÙØ§Ø¡Ø©: Ù†Ø­Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„Ø®Ø§Ø¯Ù…

---

### 2. load_from_firebase Method

```python
def load_from_firebase(self):
    """ÙŠØ­Ù…Ù„ Ø¬Ù…ÙŠØ¹ encodings Ù…Ù† Firebase"""
    
    # 1. Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ collection users
    users_ref = self.firebase_service.db.collection('users')
    docs = users_ref.stream()  # Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
    
    # 2. Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
    for doc in docs:
        user_data = doc.to_dict()  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¥Ù„Ù‰ dictionary
        
        # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        name = user_data.get('name')
        user_id = user_data.get('numericId')
        encoding_data = user_data.get('faceEncoding')
        
        # 4. Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ‡ encodingØŒ Ù†Ø¶ÙŠÙÙ‡ Ù„Ù„Ù‚ÙˆØ§Ø¦Ù…
        if encoding_data and name:
            encoding = np.array(encoding_data)  # ØªØ­ÙˆÙŠÙ„ list Ø¥Ù„Ù‰ NumPy array
            self.known_face_encodings.append(encoding)
            self.known_face_names.append(name)
            self.known_face_ids.append(user_id)
    
    return count > 0
```

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
```python
# Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ØªØ¨Ø¯Ùˆ Ù‡ÙƒØ°Ø§:
known_face_encodings = [
    array([0.123, -0.456, ..., 0.321]),  # John's encoding
    array([0.234, -0.567, ..., 0.432]),  # Jane's encoding
    array([0.345, -0.678, ..., 0.543])   # Ahmed's encoding
]
known_face_names = ["John Doe", "Jane Smith", "Ahmed Ali"]
known_face_ids = [2, 3, 4]
```

---

### 3. recognize_face Method

```python
def recognize_face(self, image_path):
    """ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬Ù‡ Ù…Ù† ØµÙˆØ±Ø©"""
    
    # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    image = face_recognition.load_image_file(image_path)
    # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¢Ù†: NumPy array Ø¨Ø­Ø¬Ù… (height, width, 3)
    
    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ face encodings Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
    face_encodings = face_recognition.face_encodings(image, model='large')
    # model='large' ÙŠØ¹Ø·ÙŠ Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù„ÙƒÙ† Ø£Ø¨Ø·Ø£
    
    # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ¬ÙˆÙ‡
    if not face_encodings:
        return None, "No face detected"
    if len(face_encodings) > 1:
        return None, "Multiple faces detected"
    
    # 4. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ encoding Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„ÙˆØ­ÙŠØ¯
    face_encoding = face_encodings[0]
    
    # 5. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙˆØ¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„Ù…Ø®Ø²Ù†Ø©
    face_distances = face_recognition.face_distance(
        self.known_face_encodings,  # Ø¬Ù…ÙŠØ¹ encodings Ø§Ù„Ù…Ø®Ø²Ù†Ø©
        face_encoding               # encoding Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    )
    # Ø§Ù„Ù†ØªÙŠØ¬Ø©: array([0.35, 0.82, 0.91, ...])
    # ÙƒÙ„ Ø±Ù‚Ù… ÙŠÙ…Ø«Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙˆÙˆØ¬Ù‡ Ù…Ø®Ø²Ù†
    
    # 6. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ threshold
    matches = face_recognition.compare_faces(
        self.known_face_encodings,
        face_encoding,
        tolerance=0.5  # Ø¥Ø°Ø§ Ø§Ù„Ù…Ø³Ø§ÙØ© < 0.5 ÙŠØ¹ØªØ¨Ø± ØªØ·Ø§Ø¨Ù‚
    )
    # Ø§Ù„Ù†ØªÙŠØ¬Ø©: [True, False, False, ...]
    
    # 7. Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚
    best_match_index = np.argmin(face_distances)
    # ÙŠØ±Ø¬Ø¹ index Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø£Ù‚Ø±Ø¨
    
    # 8. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚
    if matches[best_match_index]:
        name = self.known_face_names[best_match_index]
        confidence = 1 - face_distances[best_match_index]
        
        # 9. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø«Ù‚Ø©
        if confidence < 0.40:  # 40% minimum confidence
            return None, f"Confidence too low ({confidence:.0%})"
        
        return name, f"Recognized: {name} ({confidence:.0%})"
    
    return None, "No match found"
```

**Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ:**
```python
# Ù„Ù†ÙØªØ±Ø¶:
face_distances = [0.35, 0.82, 0.91]  # Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
known_face_names = ["John", "Jane", "Ahmed"]

# Ø£Ù‚Ù„ Ù…Ø³Ø§ÙØ© = 0.35 (index 0)
best_match_index = 0
name = "John"
confidence = 1 - 0.35 = 0.65 = 65%

# Ø§Ù„Ù†ØªÙŠØ¬Ø©: "Recognized: John (65%)"
```

---

### 4. three_step_verify Endpoint

```python
@app.route('/three-step-verify', methods=['POST'])
def three_step_verify():
    # 1. Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    data = request.get_json()
    image_data = data['image'].split(',')[1]  # Ø¥Ø²Ø§Ù„Ø© "data:image/jpeg;base64,"
    expected_numeric_id = data['expected_numeric_id']
    
    # 2. ØªØ­ÙˆÙŠÙ„ base64 Ø¥Ù„Ù‰ bytes
    image_bytes = base64.b64decode(image_data)
    
    # 3. Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
        temp_file.write(image_bytes)
        temp_path = temp_file.name
    
    try:
        # 4. Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬Ù‡
        recognized_name, message = face_model.recognize_face(temp_path)
        
        # 5. Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù‚Ù‚
        verification_result = {
            'step1_face_recognition': {
                'success': bool(recognized_name),
                'recognized_name': recognized_name,
                'message': message
            },
            'step2_numeric_id_verification': {'success': False},
            'overall_success': False
        }
        
        # 6. Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ¹Ø±ÙØŒ Ù†Ø±Ø¬Ø¹ Ù…Ø¨Ø§Ø´Ø±Ø©
        if not recognized_name:
            return jsonify(verification_result)
        
        # 7. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Firebase
        users_ref = firebase_service.db.collection('users')
        query = users_ref.where('name', '==', recognized_name)
        docs = query.get()
        
        firebase_user = docs[0].to_dict()
        firebase_numeric_id = firebase_user.get('numericId')
        
        # 8. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        numeric_id_match = (firebase_numeric_id == expected_numeric_id)
        
        # 9. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†ØªÙŠØ¬Ø©
        verification_result['step2_numeric_id_verification'] = {
            'success': numeric_id_match,
            'firebase_numeric_id': firebase_numeric_id,
            'expected_numeric_id': expected_numeric_id
        }
        
        if numeric_id_match:
            verification_result['overall_success'] = True
        
        return jsonify(verification_result)
        
    finally:
        # 10. Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        os.unlink(temp_path)
```

---

## âš›ï¸ Frontend Code Explanation

### 1. useCamera Hook

```typescript
export const useCamera = () => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string>('');

  const startCamera = async () => {
    try {
      // 1. Ø·Ù„Ø¨ Ø¥Ø°Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'  // Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©
        }
      });
      
      // 2. Ø±Ø¨Ø· stream Ø¨Ø¹Ù†ØµØ± video
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
      }
      
      setStream(mediaStream);
    } catch (err) {
      setError('Camera access denied');
    }
  };

  const captureImage = (): string | null => {
    if (!videoRef.current) return null;
    
    // 1. Ø¥Ù†Ø´Ø§Ø¡ canvas
    const canvas = document.createElement('canvas');
    canvas.width = videoRef.current.videoWidth;
    canvas.height = videoRef.current.videoHeight;
    
    // 2. Ø±Ø³Ù… Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† video Ø¥Ù„Ù‰ canvas
    const ctx = canvas.getContext('2d');
    ctx?.drawImage(videoRef.current, 0, 0);
    
    // 3. ØªØ­ÙˆÙŠÙ„ canvas Ø¥Ù„Ù‰ base64
    return canvas.toDataURL('image/jpeg', 0.95);
  };

  const stopCamera = () => {
    // Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ tracks
    stream?.getTracks().forEach(track => track.stop());
    setStream(null);
  };

  return { videoRef, startCamera, captureImage, stopCamera, error };
};
```

**ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ØŸ**
```
1. startCamera() ÙŠØ·Ù„Ø¨ Ø¥Ø°Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
2. Ø§Ù„Ù…ØªØµÙØ­ ÙŠØ¹Ø±Ø¶ Ù†Ø§ÙØ°Ø© "Allow camera access?"
3. Ø¥Ø°Ø§ ÙˆØ§ÙÙ‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ MediaStream
4. MediaStream ÙŠÙØ±Ø¨Ø· Ø¨Ø¹Ù†ØµØ± <video>
5. Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙŠØ¸Ù‡Ø± Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø©
6. Ø¹Ù†Ø¯ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ CaptureØŒ ÙŠÙØ±Ø³Ù… frame ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ canvas
7. Canvas ÙŠÙØ­ÙˆÙ„ Ø¥Ù„Ù‰ base64 string
```

---

### 2. performThreeStepAuthentication Function

```typescript
export async function performThreeStepAuthentication(
  capturedImageData: string,
  user: User
): Promise<ThreeStepVerificationResult> {
  
  console.log(`Starting authentication for ${user.name}`);
  
  // 1. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ù€ Backend
  const response = await fetch("http://localhost:5001/three-step-verify", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      image: capturedImageData,  // "data:image/jpeg;base64,..."
      expected_numeric_id: user.numericId
    }),
  });

  // 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„Ø·Ù„Ø¨
  if (!response.ok) {
    throw new Error(`Server error: ${response.status}`);
  }

  // 3. Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
  const result: ThreeStepVerificationResult = await response.json();
  
  // 4. Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„ØªØªØ¨Ø¹
  console.log("Results:", {
    step1: result.step1_face_recognition.success ? "âœ“" : "âœ—",
    step2: result.step2_numeric_id_verification.success ? "âœ“" : "âœ—",
    overall: result.overall_success ? "âœ“" : "âœ—"
  });

  return result;
}
```

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©:**
```typescript
// Ù†Ø¬Ø§Ø­:
{
  step1_face_recognition: {
    success: true,
    recognized_name: "John Doe",
    message: "Recognized: John Doe (85%)"
  },
  step2_numeric_id_verification: {
    success: true,
    firebase_numeric_id: 5,
    expected_numeric_id: 5,
    message: "IDs match"
  },
  overall_success: true
}

// ÙØ´Ù„:
{
  step1_face_recognition: {
    success: false,
    message: "No face detected"
  },
  step2_numeric_id_verification: {
    success: false
  },
  overall_success: false,
  error: "Face not recognized"
}
```

---

### 3. markAttendance Function

```typescript
export const markAttendance = async (
  userId: string,
  userName: string
): Promise<void> => {
  
  // 1. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ
  const now = new Date();
  const date = now.toISOString().split('T')[0];  // "2024-01-15"
  const time = now.toLocaleTimeString('en-US', { 
    hour12: false,
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit'
  });  // "09:00:00"
  
  // 2. ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø¶ÙˆØ±
  const workStartTime = '09:00:00';
  const isLate = time > workStartTime;
  
  // 3. Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø§Ù„Ø­Ø¶ÙˆØ±
  const attendanceData = {
    userId: userId,
    employeeName: userName,
    date: date,
    checkIn: time,
    status: isLate ? 'Late' : 'Present',
    timestamp: serverTimestamp()  // Firebase server timestamp
  };
  
  // 4. Ø­ÙØ¸ ÙÙŠ Firebase
  await addDoc(collection(db, 'attendance'), attendanceData);
  
  // 5. ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
  await updateDoc(doc(db, 'users', userId), {
    status: 'Active',
    lastLogin: serverTimestamp()
  });
};
```

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©:**
```javascript
{
  userId: "user_0005_john.doe",
  employeeName: "John Doe",
  date: "2024-01-15",
  checkIn: "09:15:00",
  status: "Late",  // Ù„Ø£Ù† 09:15 > 09:00
  timestamp: Timestamp(1705308900)
}
```

---

### 4. getUsers Function

```typescript
export const getUsers = async (): Promise<User[]> => {
  // 1. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ reference Ù„Ù„Ù€ collection
  const usersCollection = collection(db, "users");
  
  // 2. Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
  const snapshot = await getDocs(usersCollection);
  
  // 3. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¥Ù„Ù‰ array Ù…Ù† User objects
  const users = snapshot.docs.map(doc => ({
    id: doc.id,           // document ID
    ...doc.data()         // Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  } as User));
  
  return users;
};
```

**ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ mapØŸ**
```typescript
// snapshot.docs ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
[
  DocumentSnapshot { id: "user_0001_admin", data: {...} },
  DocumentSnapshot { id: "user_0002_john", data: {...} },
  DocumentSnapshot { id: "user_0003_jane", data: {...} }
]

// Ø¨Ø¹Ø¯ map:
[
  { id: "user_0001_admin", name: "Admin", numericId: 1, ... },
  { id: "user_0002_john", name: "John Doe", numericId: 2, ... },
  { id: "user_0003_jane", name: "Jane Smith", numericId: 3, ... }
]
```

---

### 5. createUserWithId Function

```typescript
export const createUserWithId = async (
  userData: Omit<User, 'id' | 'numericId'>
): Promise<User> => {
  
  // 1. ØªÙˆÙ„ÙŠØ¯ Ø±Ù‚Ù… ÙˆØ¸ÙŠÙÙŠ Ø¬Ø¯ÙŠØ¯
  const numericId = await getNextUserId();
  // Ù…Ø«Ø§Ù„: Ø¥Ø°Ø§ Ø¢Ø®Ø± Ø±Ù‚Ù… = 14ØŒ ÙŠØ±Ø¬Ø¹ 15
  
  // 2. Ø¥Ù†Ø´Ø§Ø¡ document ID
  const documentId = `user_${numericId.toString().padStart(4, '0')}_${userData.username}`;
  // Ù…Ø«Ø§Ù„: "user_0015_ahmed.ali"
  
  // 3. Ø¥Ù†Ø´Ø§Ø¡ reference Ù„Ù„Ù…Ø³ØªÙ†Ø¯
  const userRef = doc(db, "users", documentId);
  
  // 4. Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒØ§Ù…Ù„
  const newUser: User = {
    id: documentId,
    numericId,
    ...userData,
    systemAnnouncements: true,
    leaveStatusUpdates: true,
    attendanceReminders: true
  };
  
  // 5. Ø­ÙØ¸ ÙÙŠ Firebase
  await setDoc(userRef, newUser);
  
  // 6. ØªÙˆÙ„ÙŠØ¯ face encoding
  if (userData.image) {
    try {
      const response = await fetch('http://localhost:5001/add-employee', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          name: userData.name,
          numericId: numericId,
          image: userData.image
        })
      });
      
      const result = await response.json();
      
      if (!result.success) {
        throw new Error('Failed to generate face encoding');
      }
    } catch (error) {
      console.error('Face encoding failed:', error);
      alert('Warning: Face encoding failed');
    }
  }
  
  return newUser;
};
```

---

## ğŸ” Session Management

### ÙƒÙŠÙ ÙŠÙØ­ÙØ¸ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ SessionØŸ

```typescript
// Ø¹Ù†Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„:
const handleLogin = async (username: string, password: string) => {
  // 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
  const users = await getUsers();
  const user = users.find(u => 
    u.username === username && u.password === password
  );
  
  if (user) {
    // 2. Ø­ÙØ¸ ÙÙŠ sessionStorage
    sessionStorage.setItem('user', JSON.stringify(user));
    
    // 3. Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø³Ø§Ø¨
    if (user.accountType === 'Admin') {
      router.push('/admin');
    } else if (user.accountType === 'Supervisor') {
      router.push('/supervisor');
    } else {
      router.push('/userData');
    }
  }
};

// ÙÙŠ Ø£ÙŠ ØµÙØ­Ø©ØŒ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
const getUserFromSession = (): User | null => {
  const userStr = sessionStorage.getItem('user');
  return userStr ? JSON.parse(userStr) : null;
};
```

---

## ğŸ“Š Dashboard Data Loading

### ÙƒÙŠÙ ØªÙØ­Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…ØŸ

```typescript
export const useDashboard = () => {
  const [stats, setStats] = useState<AttendanceStats | null>(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const loadData = async () => {
      try {
        // 1. Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
        const users = await getUsers();
        
        // 2. Ø¬Ù„Ø¨ Ø­Ø¶ÙˆØ± Ø§Ù„ÙŠÙˆÙ…
        const todayAttendance = await getTodayAttendance();
        
        // 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        const totalMembers = users.filter(u => u.numericId !== 1).length;
        const presentToday = todayAttendance.length;
        const absentToday = totalMembers - presentToday;
        const lateToday = todayAttendance.filter(r => r.status === 'Late').length;
        
        // 4. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
        setStats({
          totalMembers,
          presentToday,
          absentToday,
          lateToday
        });
      } catch (error) {
        console.error('Error loading dashboard:', error);
      } finally {
        setLoading(false);
      }
    };

    loadData();
  }, []);

  return { stats, loading };
};
```

---

Ù‡Ø°Ø§ Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹!
